#!/usr/bin/env node

const fs = require('fs').promises;
const path = require('path');
const chokidar = require('chokidar');
const { glob } = require('glob');

class DocsAggregator {
  constructor(config = {}) {
    this.sourceDir = config.sourceDir || './docs';
    this.outputFile = config.outputFile || './aggregated-docs.md';
    this.includePatterns = config.includePatterns || ['**/*.md', '**/*.txt'];
    this.excludePatterns = config.excludePatterns || ['**/node_modules/**', '**/dist/**'];
    this.watchMode = config.watch || false;
    this.addMetadata = config.metadata !== false;
    this.addTableOfContents = config.toc !== false;
  }

  async findDocFiles() {
    const files = [];
    
    for (const pattern of this.includePatterns) {
      const matches = await glob(pattern, {
        cwd: this.sourceDir,
        ignore: this.excludePatterns,
        absolute: false
      });
      files.push(...matches);
    }
    
    // Remove duplicates and sort
    return [...new Set(files)].sort();
  }

  async readFile(filePath) {
    const fullPath = path.join(this.sourceDir, filePath);
    try {
      const content = await fs.readFile(fullPath, 'utf-8');
      return { path: filePath, content, error: null };
    } catch (error) {
      console.error(`Error reading ${filePath}:`, error.message);
      return { path: filePath, content: '', error: error.message };
    }
  }

  generateTableOfContents(files) {
    let toc = '# üìö Documentation Table of Contents\n\n';
    
    // Group files by directory
    const filesByDir = {};
    files.forEach(file => {
      const dir = path.dirname(file.path) === '.' ? 'Root' : path.dirname(file.path);
      if (!filesByDir[dir]) filesByDir[dir] = [];
      filesByDir[dir].push(file.path);
    });
    
    Object.keys(filesByDir).sort().forEach(dir => {
      toc += `\n## üìÅ ${dir}\n`;
      filesByDir[dir].forEach(file => {
        const fileName = path.basename(file);
        const anchor = file.replace(/[\/\s\.]/g, '-').toLowerCase();
        toc += `- [${fileName}](#${anchor})\n`;
      });
    });
    
    return toc + '\n---\n\n';
  }

  formatDocument(file) {
    let formatted = '';
    
    // Add file header with metadata
    const fileName = path.basename(file.path);
    const anchor = file.path.replace(/[\/\s\.]/g, '-').toLowerCase();
    
    formatted += `<a id="${anchor}"></a>\n\n`;
    formatted += `# üìÑ ${fileName}\n\n`;
    
    if (this.addMetadata) {
      formatted += `> **File Path:** \`${file.path}\`\n`;
      formatted += `> **Last Synced:** ${new Date().toISOString()}\n`;
      if (file.error) {
        formatted += `> **‚ö†Ô∏è Error:** ${file.error}\n`;
      }
      formatted += '\n';
    }
    
    // Add content
    if (file.content) {
      formatted += file.content;
    } else if (file.error) {
      formatted += `‚ö†Ô∏è Could not read file: ${file.error}\n`;
    }
    
    formatted += '\n\n---\n\n';
    return formatted;
  }

  async aggregate() {
    console.log('üîç Searching for documentation files...');
    const filePaths = await this.findDocFiles();
    
    if (filePaths.length === 0) {
      console.log('No documentation files found.');
      return;
    }
    
    console.log(`üìö Found ${filePaths.length} documentation files`);
    
    // Read all files
    const files = await Promise.all(
      filePaths.map(filePath => this.readFile(filePath))
    );
    
    // Generate aggregated content
    let aggregatedContent = '';
    
    // Add header
    aggregatedContent += '# üéå Moshimoshi Project Documentation\n\n';
    aggregatedContent += `> Auto-generated on ${new Date().toISOString()}\n`;
    aggregatedContent += `> Total documents: ${files.length}\n\n`;
    aggregatedContent += '---\n\n';
    
    // Add table of contents
    if (this.addTableOfContents) {
      aggregatedContent += this.generateTableOfContents(files);
    }
    
    // Add each document
    files.forEach(file => {
      aggregatedContent += this.formatDocument(file);
    });
    
    // Add footer
    aggregatedContent += '\n---\n\n';
    aggregatedContent += `*Generated by docs-aggregator.js at ${new Date().toISOString()}*\n`;
    aggregatedContent += `*Source: ${this.sourceDir}*\n`;
    
    // Write to output file
    await fs.writeFile(this.outputFile, aggregatedContent, 'utf-8');
    
    const stats = await fs.stat(this.outputFile);
    const sizeMB = (stats.size / (1024 * 1024)).toFixed(2);
    
    console.log(`‚úÖ Aggregated documentation written to: ${this.outputFile}`);
    console.log(`üìä File size: ${sizeMB} MB`);
    console.log(`üìù Documents included: ${files.length}`);
    
    return { filePaths, outputFile: this.outputFile, size: sizeMB };
  }

  async watch() {
    // Initial aggregation
    await this.aggregate();
    
    console.log('\nüëÄ Watching for changes...');
    
    // Set up file watcher
    const watchPaths = this.includePatterns.map(pattern => 
      path.join(this.sourceDir, pattern)
    );
    
    const watcher = chokidar.watch(watchPaths, {
      ignored: this.excludePatterns,
      persistent: true,
      ignoreInitial: true
    });
    
    // Debounce function to avoid multiple rapid updates
    let debounceTimer;
    const debouncedAggregate = () => {
      clearTimeout(debounceTimer);
      debounceTimer = setTimeout(async () => {
        console.log('\n‚ôªÔ∏è  Changes detected, re-aggregating...');
        await this.aggregate();
        console.log('üëÄ Continuing to watch for changes...\n');
      }, 1000); // Wait 1 second after last change
    };
    
    watcher
      .on('add', path => {
        console.log(`‚ûï File added: ${path}`);
        debouncedAggregate();
      })
      .on('change', path => {
        console.log(`üìù File changed: ${path}`);
        debouncedAggregate();
      })
      .on('unlink', path => {
        console.log(`üóëÔ∏è  File removed: ${path}`);
        debouncedAggregate();
      })
      .on('error', error => {
        console.error('‚ùå Watcher error:', error);
      });
    
    // Handle graceful shutdown
    process.on('SIGINT', () => {
      console.log('\n\nüëã Stopping file watcher...');
      watcher.close();
      process.exit(0);
    });
  }

  async run() {
    if (this.watchMode) {
      await this.watch();
    } else {
      await this.aggregate();
    }
  }
}

// CLI interface
if (require.main === module) {
  const args = process.argv.slice(2);
  
  const config = {
    sourceDir: './docs',
    outputFile: './aggregated-docs.md',
    watch: false,
    metadata: true,
    toc: true
  };
  
  // Parse command line arguments
  for (let i = 0; i < args.length; i++) {
    switch (args[i]) {
      case '--watch':
      case '-w':
        config.watch = true;
        break;
      case '--source':
      case '-s':
        config.sourceDir = args[++i];
        break;
      case '--output':
      case '-o':
        config.outputFile = args[++i];
        break;
      case '--no-metadata':
        config.metadata = false;
        break;
      case '--no-toc':
        config.toc = false;
        break;
      case '--help':
      case '-h':
        console.log(`
üìö Documentation Aggregator for NotebookLM

Usage: node scripts/docs-aggregator.js [options]

Options:
  -w, --watch          Watch for file changes and auto-sync
  -s, --source <dir>   Source directory (default: ./docs)
  -o, --output <file>  Output file (default: ./aggregated-docs.md)
  --no-metadata        Don't add file metadata
  --no-toc            Don't add table of contents
  -h, --help          Show this help message

Examples:
  # One-time aggregation
  node scripts/docs-aggregator.js
  
  # Watch mode with auto-sync
  node scripts/docs-aggregator.js --watch
  
  # Custom directories
  node scripts/docs-aggregator.js -s ./documentation -o ./notebookml-upload.md
  
  # Include TypeScript files too
  node scripts/docs-aggregator.js --include "**/*.ts"
`);
        process.exit(0);
    }
  }
  
  const aggregator = new DocsAggregator(config);
  aggregator.run().catch(error => {
    console.error('‚ùå Error:', error);
    process.exit(1);
  });
}

module.exports = DocsAggregator;